{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f929e9a9-d6c3-4857-b9b5-bc4f267955f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qibo.symbols import Z\n",
    "from qibo import hamiltonians\n",
    "\n",
    "from qiboml.models.encoding_decoding import *\n",
    "from qiboml.models.ansatze import *\n",
    "\n",
    "def run_model(model, x):\n",
    "    for layer in model:\n",
    "        x = layer.forward(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cccd24-dece-4279-bcd2-7006582458c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0. 1. 0. 0. 0.], shape=(8,), dtype=float64)\n",
      "tf.Tensor([0. 0. 1. 0. 0. 0. 0. 0.], shape=(8,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 1. 0. 0. 0.], shape=(8,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# binary data\n",
    "model = [BinaryEncodingLayer(nqubits=3), ReuploadingLayer(nqubits=3, qubits=(0,2)), QuantumDecodingLayer(nqubits=3, qubits=(1,0))]\n",
    "data = np.array([[0,0,0], [0,1,0], [1,1,0]])\n",
    "\n",
    "for x in data:\n",
    "    print(run_model(model, x).probabilities())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005b4456-baab-486d-901a-0834ee042f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Qibo 0.2.10|INFO|2024-07-12 10:41:57]: Using qibojit (numba) backend on /CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5069999999999999\n",
      "0.512\n",
      "0.5209999999999999\n"
     ]
    }
   ],
   "source": [
    "# real data\n",
    "nqubits = 4\n",
    "observable = hamiltonians.SymbolicHamiltonian(np.prod([Z(q) for q in range(nqubits)]))\n",
    "model = [PhaseEncodingLayer(nqubits, qubits=range(3)), ReuploadingLayer(nqubits), ExpectationLayer(nqubits, observable=observable, nshots=1000)]\n",
    "data = np.pi * np.random.randn(3**2).reshape(3, 3)\n",
    "\n",
    "for x in data:\n",
    "    print(run_model(model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3f3599-b477-4725-8b27-16e5ba5c151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# pytorch interface\\nimport torch\\nimport qiboml.models.pytorch as pt\\n\\nnqubits = 5\\nobservable = hamiltonians.SymbolicHamiltonian(np.prod([Z(q) for q in range(nqubits)]))\\n\\nmodel = torch.nn.Sequential(\\n    torch.nn.Linear(128,5),\\n    torch.nn.Sigmoid(),\\n    pt.BinaryEncodingLayer(5),\\n    pt.ReuploadingLayer(nqubits=5, qubits=(0,2,4)),\\n    pt.QuantumDecodingLayer(nqubits=5, qubits=reversed(range(5))),\\n    #pt.ExpectationLayer(nqubits=5, qubits=reversed(range(5)), observable=observable),\\n)\\n\\nprint(f\"> Model: {model}\")\\nprint(\"> Parameters\")\\nfor name, param in model.named_parameters():\\n    if param.requires_grad:\\n        print(name, param.shape)\\n\\ndata = torch.randn(3, 128)\\nprint(\"> Outputs\")\\nfor x in data:\\n    print(model(x).probabilities())\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# pytorch interface\n",
    "import torch\n",
    "import qiboml.models.pytorch as pt\n",
    "\n",
    "nqubits = 5\n",
    "observable = hamiltonians.SymbolicHamiltonian(np.prod([Z(q) for q in range(nqubits)]))\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(128,5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    pt.BinaryEncodingLayer(5),\n",
    "    pt.ReuploadingLayer(nqubits=5, qubits=(0,2,4)),\n",
    "    pt.QuantumDecodingLayer(nqubits=5, qubits=reversed(range(5))),\n",
    "    #pt.ExpectationLayer(nqubits=5, qubits=reversed(range(5)), observable=observable),\n",
    ")\n",
    "\n",
    "print(f\"> Model: {model}\")\n",
    "print(\"> Parameters\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "\n",
    "data = torch.randn(3, 128)\n",
    "print(\"> Outputs\")\n",
    "for x in data:\n",
    "    print(model(x).probabilities())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47ac400-88f7-44e7-ae20-cb117c2da136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7616, dtype=torch.float64)\n",
      "tensor(0.7616, dtype=torch.float64)\n",
      "tensor(0.7616, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import qiboml.models.pytorch as pt\n",
    "import qiboml.models.encoding_decoding as ed\n",
    "import qiboml.models.ansatze as ans\n",
    "\n",
    "q_model = pt.QuantumModel(\n",
    "    layers = [\n",
    "        ed.BinaryEncodingLayer(5),\n",
    "        ans.ReuploadingLayer(nqubits=5, qubits=(0,2,4)),\n",
    "        ed.ExpectationLayer(nqubits=5, qubits=reversed(range(5)), observable=observable, nshots=1000),\n",
    "    ]\n",
    ")\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(128,5),\n",
    "    torch.nn.Hardshrink(),\n",
    "    q_model,\n",
    "    torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "for x in torch.randn(3,128):\n",
    "    print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43a1c4b-2186-4022-bf75-97d559d68d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Model: <Sequential name=sequential, built=False>\n",
      "> Outputs\n",
      "0.4252\n",
      "0.39999999999999997\n",
      "0.39640000000000003\n"
     ]
    }
   ],
   "source": [
    "# keras/tensorflow interface\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import qiboml.models.keras as ks\n",
    "import qiboml.models.encoding_decoding as ed\n",
    "import qiboml.models.ansatze as ans\n",
    "\n",
    "nqubits = 5\n",
    "observable = hamiltonians.SymbolicHamiltonian(np.prod([Z(q) for q in range(nqubits)]))\n",
    "\n",
    "q_model = ks.QuantumModel(\n",
    "    layers = [\n",
    "        ed.PhaseEncodingLayer(5),\n",
    "        ans.ReuploadingLayer(nqubits=5, qubits=(0,2,4)),\n",
    "        ed.ExpectationLayer(nqubits=5, qubits=reversed(range(5)), observable=observable, nshots=1000)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(5, activation=\"sigmoid\", name=\"dense\"),\n",
    "    q_model,\n",
    "])\n",
    "\n",
    "\n",
    "print(f\"> Model: {model}\")\n",
    "\n",
    "data = tf.random.uniform((3,128))\n",
    "print(\"> Outputs\")\n",
    "for x in data:\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    print(model(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c28c9-8622-4e5d-b2e7-800e0e79731a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
