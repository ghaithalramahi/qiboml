import torch

import qiboml.models.encoding_decoding as encodings
from qiboml.models.abstract import QuantumCircuitLayer



def __init__factory(layer):
    def __init__(cls, *args, **kwargs):
        nonlocal layer
        torch.nn.Module.__init__(cls)
        layer.__init__(cls, *args, **kwargs)
        cls.register_parameter(layer.circuit.get_parameters())
    return __init__

for name, layer in encodings.__dict__.items():
    if isinstance(layer, type):
        #breakpoint()
        newcls = type(
            name,
            (torch.nn.Module, layer),
            {"__init__": __init__factory(layer), }
        )

"""
def forward(cls, x, **kwargs):
    return cls.layer.forward(x, **kwargs)

def backward(cls, input_grad, **kwargs):
    return cls.layer.backward(input_grad, **kwargs)

class TorchWrapper(torch.nn.Module):

    def __init__(self, layer: QuantumCircuitLayer.__class__, *args, **kwargs) -> None:
        super().__init__()
        self.layer = layer.__init__(*args, **kwargs)
        self.register_parameter(self.layer.circuit.get_parameters())

    def forward(self, x, **kwargs):
        return self.layer.forward(x, **kwargs)

    def backward(self, input_grad, **kwargs):
        return self.layer.backward(input_grad, **kwargs)


class TorchFactory(type):

    def __new__(cls, name, layer):
        return super().__new__(
            cls,
            name,
            (torch.nn.Module, ),
            {"layer": None, "__init__": __init__, "forward": layer.forward, "backward": layer.backward}
        )
"""
